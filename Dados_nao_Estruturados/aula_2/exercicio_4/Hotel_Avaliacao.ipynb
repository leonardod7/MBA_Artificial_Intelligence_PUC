{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Análise de avaliações de hotéis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "### 1. Observação inicial dos dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text class\n0                                vocês são o melhor    pos\n1               foi muito grato trabalhar com voces    pos\n2  realizei o aniversario de meu sobrinho na terc...   pos\n3       gostei muito do atendimento personalizado/n    pos\n4  grande hotel com otimas acomodacoes, a beira d...   pos",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>vocês são o melhor</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>foi muito grato trabalhar com voces</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>realizei o aniversario de meu sobrinho na terc...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>gostei muito do atendimento personalizado/n</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>grande hotel com otimas acomodacoes, a beira d...</td>\n      <td>pos</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install liac-arff\n",
    "import arff\n",
    "import pandas as pd\n",
    "\n",
    "dataset = arff.load(open('hoteis.arff', 'r', encoding=\"ISO-8859-1\"))\n",
    "data = pd.DataFrame(dataset['data'])\n",
    "data.columns = ['text', 'class']\n",
    "\n",
    "# Estrutura dos dados\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.iloc[100,0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Quantidade de linhas\n",
    "\n",
    "print(data.shape[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Existem valores nulos (por coluna)?\n",
    "\n",
    "print(data.isnull().any())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Quantidade de avaliações positivas e negativas\n",
    "\n",
    "data['class'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Separação dos dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separação do label e das features\n",
    "X = data.drop('class', axis=1).values\n",
    "y = data['class'].values\n",
    "\n",
    "# Separação de dados de treino e teste\n",
    "train_features, test_features, class_train, class_test = train_test_split(X, y, test_size=0.20, random_state=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. StopWords"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. CountVectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Criação de matriz com a contagem de cada token SEM stop words\n",
    "cv = CountVectorizer(max_features=10000)\n",
    "cv_train_features = cv.fit_transform(train_features.ravel())\n",
    "cv_test_features = cv.transform(test_features.ravel())\n",
    "\n",
    "print('Shape das features de treino:', cv_train_features.shape, ' Shape das features de teste:', cv_test_features.shape)\n",
    "\n",
    "# Criação de matriz com a contagem de cada token COM stop words\n",
    "cv_sw = CountVectorizer(stop_words = stopwords.words('portuguese'),max_features=10000)\n",
    "cv_sw_train_features = cv_sw.fit_transform(train_features.ravel())\n",
    "cv_sw_test_features = cv_sw.transform(test_features.ravel())\n",
    "\n",
    "\n",
    "print('Shape das features de treino:', cv_sw_train_features.shape, ' Shape das features de teste:', cv_sw_test_features.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Funções Auxiliares"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def train_predict_model(classifier,\n",
    "                        train_features, train_labels,\n",
    "                        test_features, test_labels):\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    predictions = classifier.predict(test_features)\n",
    "    return predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n",
    "\n",
    "    total_classes = len(classes)\n",
    "    level_labels = [total_classes*[0], list(range(total_classes))]\n",
    "\n",
    "    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels,\n",
    "                                  labels=classes)\n",
    "\n",
    "    cm_frame = pd.DataFrame(cm, index=classes, columns=classes,)\n",
    "    cm_frame.index.name = 'Actual'\n",
    "    cm_frame.columns.name = 'Predicted'\n",
    "\n",
    "    print(cm_frame)\n",
    "\n",
    "def display_classification_report(true_labels, predicted_labels, classes=[1,0]):\n",
    "\n",
    "    report = metrics.classification_report(y_true=true_labels,\n",
    "                                           y_pred=predicted_labels,\n",
    "                                           labels=classes)\n",
    "    print(report)\n",
    "\n",
    "def display_model_performance_metrics(true_labels, predicted_labels, classes=[1,0]):\n",
    "    print('Model Performance metrics:')\n",
    "    print('-'*30)\n",
    "    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n",
    "    print('\\nModel Classification report:')\n",
    "    print('-'*30)\n",
    "    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels,\n",
    "                                  classes=classes)\n",
    "    print('\\nPrediction Confusion Matrix:')\n",
    "    print('-'*30)\n",
    "    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels,\n",
    "                             classes=classes)\n",
    "\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "\n",
    "    print('Accuracy:', np.round(\n",
    "                        metrics.accuracy_score(true_labels,\n",
    "                                               predicted_labels),\n",
    "                        4))\n",
    "    print('Precision:', np.round(\n",
    "                        metrics.precision_score(true_labels,\n",
    "                                               predicted_labels,\n",
    "                                               average='weighted'),\n",
    "                        4))\n",
    "    print('Recall:', np.round(\n",
    "                        metrics.recall_score(true_labels,\n",
    "                                               predicted_labels,\n",
    "                                               average='weighted'),\n",
    "                        4))\n",
    "    print('F1 Score:', np.round(\n",
    "                        metrics.f1_score(true_labels,\n",
    "                                               predicted_labels,\n",
    "                                               average='weighted'),\n",
    "                        4))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6.1 RF com stop words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=10)\n",
    "\n",
    "rfc_tfidf_predictions = train_predict_model(classifier=rfc,\n",
    "                                                train_features=cv_sw_train_features, train_labels=class_train,\n",
    "                                                test_features=cv_sw_test_features, test_labels=class_test)\n",
    "\n",
    "display_model_performance_metrics(true_labels=class_test, predicted_labels=rfc_tfidf_predictions,classes=['pos', 'neg'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6.2 RF sem stop words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfc_tfidf_predictions = train_predict_model(classifier=rfc,\n",
    "                                                train_features=cv_train_features, train_labels=class_train,\n",
    "                                                test_features=cv_test_features, test_labels=class_test)\n",
    "\n",
    "display_model_performance_metrics(true_labels=class_test, predicted_labels=rfc_tfidf_predictions,classes=['pos', 'neg'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "O valor tf–idf, é uma medida estatística que tem o intuito de indicar a importância de uma palavra de um documento em relação a uma coleção de documentos ou em um corpus linguístico. Ela é frequentemente utilizada como fator de ponderação na recuperação de informações e na mineração de dados.\n",
    "\n",
    "O valor tf–idf de uma palavra aumenta proporcionalmente à medida que aumenta o número de ocorrências dela em um documento, no entanto, esse valor é equilibrado pela frequência da palavra no corpus. Isso auxilia a distinguir o fato da ocorrência de algumas palavras serem geralmente mais comuns que outras."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1,2),\n",
    "                     sublinear_tf=True)\n",
    "tv_train_features = tv.fit_transform(train_features.ravel())\n",
    "tv_test_features = tv.transform(test_features.ravel())\n",
    "\n",
    "print('Shape das features de treino:', tv_train_features.shape, ' Shape das features de teste:', tv_test_features.shape, '\\n')\n",
    "\n",
    "rfc_tfidf_predictions = train_predict_model(classifier=rfc,\n",
    "                                               train_features=tv_train_features, train_labels=class_train,\n",
    "                                               test_features=tv_test_features, test_labels=class_test)\n",
    "display_model_performance_metrics(true_labels=class_test, predicted_labels=rfc_tfidf_predictions,classes=['pos', 'neg'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8. STEMMER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nltk.download('rslp')\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "X = data.drop('class', axis=1).values\n",
    "y = data['class'].values\n",
    "\n",
    "corpus = []\n",
    "for review in data['text']:\n",
    "    phrase = []\n",
    "    for word in review.split():\n",
    "        w_stemmed = stemmer.stem(word)\n",
    "        phrase.append(w_stemmed)\n",
    "    corpus.append(phrase)\n",
    "# Separate data into train and test\n",
    "train_features, test_features, class_train, class_test = train_test_split(corpus, y, test_size=0.20, random_state=10)\n",
    "\n",
    "rfc_stem_predictions = train_predict_model(classifier=rfc,\n",
    "                                               train_features=tv_train_features, train_labels=class_train,\n",
    "                                               test_features=tv_test_features, test_labels=class_test)\n",
    "display_model_performance_metrics(true_labels=class_test, predicted_labels=rfc_stem_predictions,classes=['pos', 'neg'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 9. Separação de palavras positivas e negativas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Palavras negativas, removendo stopwords\n",
    "\n",
    "neg_phrases = data[data['class'] == 'neg']\n",
    "neg_string = []\n",
    "for phrase in neg_phrases['text']:\n",
    "    for word in phrase.split():\n",
    "        if word not in stopwords.words('portuguese'):\n",
    "            neg_string.append(word)\n",
    "\n",
    "neg_text = pd.Series(neg_string).str.cat(sep=' ')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Palavras positivas, removendo stopwords\n",
    "\n",
    "pos_phrases = data[data['class'] == 'pos']\n",
    "pos_string = []\n",
    "for phrase in pos_phrases['text']:\n",
    "    for word in phrase.split():\n",
    "        if word not in stopwords.words('portuguese'):\n",
    "            pos_string.append(word)\n",
    "\n",
    "pos_text = pd.Series(pos_string).str.cat(sep=' ')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 10. WordCloud"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Word cloud de palavras negativas\n",
    "# !pip install wordcloud"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wordcloud = WordCloud(width=1600, height=800, max_font_size=200).generate(neg_text)\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Word cloud de palavras positivas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=1600, height=800, max_font_size=200).generate(pos_text)\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
